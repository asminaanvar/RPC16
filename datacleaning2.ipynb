{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da4391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from 'aqi.csv'.\n",
      "The 'date' column has been successfully converted to datetime objects.\n",
      "'aqi_value' is already of dtype: int64. No conversion needed.\n",
      "\n",
      "--- Analyzing AQI on Weekends vs Weekdays in Indian Metro Cities (Last 1 Year) ---\n",
      "Considering data from 25-07-2024 to 25-07-2025.\n",
      "\n",
      "--- Average AQI: Weekends vs. Weekdays in Metro Cities (Last 1 Year) ---\n",
      "day_type   Weekday  Weekend\n",
      "area                       \n",
      "Ahmedabad   117.23   120.11\n",
      "Bengaluru    76.83    76.82\n",
      "Chennai      73.07    68.54\n",
      "Delhi       220.51   206.34\n",
      "Hyderabad    82.98    83.12\n",
      "Kolkata     103.73   103.32\n",
      "Mumbai       99.97   102.56\n",
      "Pune        110.56   109.39\n",
      "\n",
      "--- Comparison of Average AQI ---\n",
      "day_type   Weekday  Weekend  Difference (Weekday - Weekend)  \\\n",
      "area                                                          \n",
      "Ahmedabad   117.23   120.11                           -2.88   \n",
      "Bengaluru    76.83    76.82                            0.01   \n",
      "Chennai      73.07    68.54                            4.53   \n",
      "Delhi       220.51   206.34                           14.18   \n",
      "Hyderabad    82.98    83.12                           -0.15   \n",
      "Kolkata     103.73   103.32                            0.41   \n",
      "Mumbai       99.97   102.56                           -2.59   \n",
      "Pune        110.56   109.39                            1.18   \n",
      "\n",
      "day_type   Weekend vs Weekday Ratio  \n",
      "area                                 \n",
      "Ahmedabad                      1.02  \n",
      "Bengaluru                      1.00  \n",
      "Chennai                        0.94  \n",
      "Delhi                          0.94  \n",
      "Hyderabad                      1.00  \n",
      "Kolkata                        1.00  \n",
      "Mumbai                         1.03  \n",
      "Pune                           0.99  \n",
      "\n",
      "Interpretation Guide:\n",
      "  - A positive 'Difference (Weekday - Weekend)' means AQI is typically higher on weekdays.\n",
      "  - A 'Weekend vs Weekday Ratio' less than 1 means AQI is typically lower on weekends (i.e., improvement).\n",
      "\n",
      "--- Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "file_name = 'aqi.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_name)\n",
    "    print(f\"Data loaded successfully from '{file_name}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_name}' was not found. Please ensure it's in the same directory as your script, or provide the full path.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 3: Convert the 'date' column to datetime objects ---\n",
    "try:\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "    print(\"The 'date' column has been successfully converted to datetime objects.\")\n",
    "except KeyError:\n",
    "    print(\"Error: 'date' column not found. Please check the column name in your data.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error converting 'date' column: {e}\")\n",
    "    print(\"Please ensure the 'date' column's format is consistently DD-MM-YYYY.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 4: Convert 'aqi_value' to numeric (if it's not already) ---\n",
    "try:\n",
    "    original_dtype_aqi = df['aqi_value'].dtype\n",
    "    if original_dtype_aqi == 'object':\n",
    "        print(f\"'{original_dtype_aqi}' dtype detected for 'aqi_value'. Attempting conversion to numeric.\")\n",
    "        df['aqi_value'] = pd.to_numeric(df['aqi_value'], errors='coerce')\n",
    "        if df['aqi_value'].isnull().any():\n",
    "            print(\"Warning: NaN values introduced in 'aqi_value' after conversion for 'aqi_value'.\")\n",
    "        else:\n",
    "            print(\"Conversion successful: 'aqi_value' is now numeric with no new NaNs.\")\n",
    "    else:\n",
    "        print(f\"'aqi_value' is already of dtype: {original_dtype_aqi}. No conversion needed.\")\n",
    "except KeyError:\n",
    "    print(\"Error: 'aqi_value' column not found. Please check the column name in your data.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 5: Analysis: AQI on Weekends vs Weekdays in Indian Metro Cities (Last 1 Year) ---\n",
    "\n",
    "print(\"\\n--- Analyzing AQI on Weekends vs Weekdays in Indian Metro Cities (Last 1 Year) ---\")\n",
    "\n",
    "# Define Indian Metro Cities (Adjust names if they differ in your 'area' column)\n",
    "# It's good practice to convert your 'area' column to title case if its casing is inconsistent.\n",
    "# df['area'] = df['area'].str.title() # Uncomment if area names have inconsistent casing\n",
    "\n",
    "metro_cities = [\n",
    "    'Delhi',\n",
    "    'Mumbai',\n",
    "    'Chennai',\n",
    "    'Kolkata',\n",
    "    'Bengaluru', # Note: 'Bengaluru' is the official name, ensure your data uses it or 'Bangalore'\n",
    "    'Hyderabad',\n",
    "    'Ahmedabad',\n",
    "    'Pune'\n",
    "]\n",
    "\n",
    "# Define the date range for \"last 1 year\" from today (July 26, 2025)\n",
    "end_date = datetime(2025, 7, 25) # Up to yesterday (July 25, 2025)\n",
    "start_date = end_date - timedelta(days=365) # One year prior\n",
    "\n",
    "print(f\"Considering data from {start_date.strftime('%d-%m-%Y')} to {end_date.strftime('%d-%m-%Y')}.\")\n",
    "\n",
    "# Filter data for metro cities and the last 1 year\n",
    "filtered_metro_df = df[\n",
    "    (df['area'].isin(metro_cities)) &\n",
    "    (df['date'] >= start_date) &\n",
    "    (df['date'] <= end_date)\n",
    "].copy()\n",
    "\n",
    "if filtered_metro_df.empty:\n",
    "    print(\"\\nNo data found for the specified metro cities in the last 1 year.\")\n",
    "    print(\"Please check city names in your 'area' column and the date range of your data.\")\n",
    "else:\n",
    "    # Create a 'day_type' column (Weekday or Weekend)\n",
    "    # Monday=0, Sunday=6\n",
    "    filtered_metro_df['day_of_week'] = filtered_metro_df['date'].dt.dayofweek\n",
    "    filtered_metro_df['day_type'] = filtered_metro_df['day_of_week'].apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')\n",
    "\n",
    "    # Calculate average AQI for each city by day type\n",
    "    aqi_comparison = filtered_metro_df.groupby(['area', 'day_type'])['aqi_value'].mean().unstack()\n",
    "\n",
    "    print(\"\\n--- Average AQI: Weekends vs. Weekdays in Metro Cities (Last 1 Year) ---\")\n",
    "    print(aqi_comparison.round(2)) # Round to 2 decimal places for readability\n",
    "\n",
    "    # Optional: Calculate the difference or ratio for easier comparison\n",
    "    if 'Weekday' in aqi_comparison.columns and 'Weekend' in aqi_comparison.columns:\n",
    "        aqi_comparison['Difference (Weekday - Weekend)'] = aqi_comparison['Weekday'] - aqi_comparison['Weekend']\n",
    "        aqi_comparison['Weekend vs Weekday Ratio'] = aqi_comparison['Weekend'] / aqi_comparison['Weekday']\n",
    "        print(\"\\n--- Comparison of Average AQI ---\")\n",
    "        print(aqi_comparison[['Weekday', 'Weekend', 'Difference (Weekday - Weekend)', 'Weekend vs Weekday Ratio']].round(2))\n",
    "\n",
    "        print(\"\\nInterpretation Guide:\")\n",
    "        print(\"  - A positive 'Difference (Weekday - Weekend)' means AQI is typically higher on weekdays.\")\n",
    "        print(\"  - A 'Weekend vs Weekday Ratio' less than 1 means AQI is typically lower on weekends (i.e., improvement).\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nCould not calculate difference/ratio as not all day types found for all cities.\")\n",
    "\n",
    "print(\"\\n--- Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3e1c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from 'aqi.csv'.\n",
      "The 'date' column has been successfully converted to datetime objects.\n",
      "considering date from 2025-03-01 00:00:00  to 2025-04-30 00:00:00\n",
      "  Air Quality Category  Number of Days\n",
      "0         Satisfactory              48\n",
      "1             Moderate              13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "file_name = 'aqi.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f\"Data loaded successfully from '{file_name}'.\")\n",
    "\n",
    "try:\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "    print(\"The 'date' column has been successfully converted to datetime objects.\")\n",
    "except KeyError:\n",
    "    print(\"Error: 'date' column not found. Please check the column name in your data.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error converting 'date' column: {e}\")\n",
    "    print(\"Please ensure the 'date' column's format is consistently DD-MM-YYYY.\")\n",
    "    exit()\n",
    "\n",
    "f_area='Bengaluru'\n",
    "\n",
    "# Define the date range from march to may ( 2025)\n",
    "end_date = datetime(2025, 4, 30) # Up to yesterday (July 25, 2025)\n",
    "start_date = datetime(2025, 3, 1)\n",
    "\n",
    "print(f\"considering date from {start_date}  to {end_date}\")\n",
    "\n",
    "filtered_df = df[\n",
    "    (df['area']==f_area) &\n",
    "    (df['date'] >= start_date) &\n",
    "    (df['date'] <= end_date)\n",
    "].copy()\n",
    "\n",
    "# Create a new DataFrame that contains the dominant status per day (e.g., the most frequent one)\n",
    "dominant_status = (\n",
    "    filtered_df.groupby(['date'])['air_quality_status']\n",
    "    .agg(lambda x: x.mode()[0])  # Use mode to get the most frequent status\n",
    ")\n",
    "\n",
    "# Now count how many days had each status\n",
    "category_day_counts = dominant_status.value_counts().reset_index()\n",
    "category_day_counts.columns = ['Air Quality Category', 'Number of Days']\n",
    "\n",
    "print(category_day_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fbbc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from 'vahan.csv'.\n",
      "Created 'EV or NonEV' columns.\n",
      "Top 5 states with highest EV adoption: ['Karnataka', 'Maharashtra', 'Uttar Pradesh', 'Rajasthan', 'Tamil Nadu']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "file_name = 'vahan.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f\"Data loaded successfully from '{file_name}'.\")\n",
    "\n",
    "\n",
    "df['EV or NonEV'] = np.where(\n",
    "    df['fuel'].isin([\"ELECTRIC(BOV)\", \"PURE EV\", \"STRONG HYBRID EV\", \"PLUG-IN HYBRID EV\"]) |\n",
    "    df['vehicle_class'].isin([\"E-RICKSHAW(P)\", \"E-RICKSHAW WITH CART (G)\"]),\n",
    "    \"EV\",\n",
    "    \"NonEV\"\n",
    ")\n",
    "\n",
    "print(\"Created 'EV or NonEV' columns.\")\n",
    "ev_df = df[df['EV or NonEV'] == 'EV']\n",
    "top_ev_states = (\n",
    "    ev_df.groupby('state')\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(5)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "print(\"Top 5 states with highest EV adoption:\", top_ev_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05e558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ev_adoption_group']=df['state'].apply(lambda x: \"High EV\" if x in top_ev_states else \"Low EV\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c046e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from 'vahan.csv'.\n",
      "Created 'EV or NonEV' columns.\n",
      "Top 5 states with highest EV adoption: ['Karnataka', 'Maharashtra', 'Uttar Pradesh', 'Rajasthan', 'Tamil Nadu']\n",
      "Average aqi_value is ev_adoption_group\n",
      "High EV    101.266680\n",
      "Low EV     119.194758\n",
      "Name: aqi_value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "file_name = 'vahan.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f\"Data loaded successfully from '{file_name}'.\")\n",
    "aqi_df = pd.read_csv('aqi.csv')\n",
    "\n",
    "\n",
    "df['EV or NonEV'] = np.where(\n",
    "    df['fuel'].isin([\"ELECTRIC(BOV)\", \"PURE EV\", \"STRONG HYBRID EV\", \"PLUG-IN HYBRID EV\"]) |\n",
    "    df['vehicle_class'].isin([\"E-RICKSHAW(P)\", \"E-RICKSHAW WITH CART (G)\"]),\n",
    "    \"EV\",\n",
    "    \"NonEV\"\n",
    ")\n",
    "\n",
    "print(\"Created 'EV or NonEV' columns.\")\n",
    "ev_df = df[df['EV or NonEV'] == 'EV']\n",
    "top_ev_states = (\n",
    "    ev_df.groupby('state')\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(5)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "print(\"Top 5 states with highest EV adoption:\", top_ev_states)\n",
    "aqi_df['ev_adoption_group']=aqi_df['state'].apply(lambda x: \"High EV\" if x in top_ev_states else \"Low EV\" )\n",
    "\n",
    "avg_aqi_by_ev_group = aqi_df.groupby('ev_adoption_group')['aqi_value'].mean()\n",
    "\n",
    "print(\"Average aqi_value is\",avg_aqi_by_ev_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d212a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T-Test: t-statistic = -62.28, p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "high_ev_aqi = aqi_df[aqi_df['ev_adoption_group'] == 'High EV']['aqi_value']\n",
    "low_ev_aqi = aqi_df[aqi_df['ev_adoption_group'] == 'Low EV']['aqi_value']\n",
    "\n",
    "t_stat, p_val = ttest_ind(high_ev_aqi, low_ev_aqi, equal_var=False)\n",
    "print(f\"\\nT-Test: t-statistic = {t_stat:.2f}, p-value = {p_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69106ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "file_name = 'vahan.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f\"Data loaded successfully from '{file_name}'.\")\n",
    "aqi_df = pd.read_csv('aqi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba17ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from aqi.csv.\n",
      "The 'date' column has been successfully converted to datetime objects.\n",
      "'aqi_value' is already of dtype: int64. No conversion needed.\n",
      "Created 'year', 'month', and 'month_name' columns.\n",
      "\n",
      "--- Export Complete ---\n",
      "Your main processed DataFrame has been saved to: 'air_quality_processed_for_powerbi.csv'\n",
      "You can now import this CSV file into Power BI Desktop.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_name = 'aqi.csv'\n",
    "\n",
    "# --- Step 2: Load the Data ---\n",
    "try:\n",
    "    df = pd.read_csv(file_name)\n",
    "    print(f\"Data loaded successfully from {file_name}.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{file_name}' not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 3: Convert the 'date' column to datetime objects ---\n",
    "try:\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "    print(\"The 'date' column has been successfully converted to datetime objects.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error converting 'date' column: {e}\")\n",
    "    print(\"Please check if the 'date' column truly follows the DD-MM-YYYY format or if its name is correct.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 4: Convert 'aqi_value' to numeric (if it's not already) ---\n",
    "# This ensures it's treated as a number in Power BI for calculations.\n",
    "original_dtype_aqi = df['aqi_value'].dtype\n",
    "if original_dtype_aqi == 'object':\n",
    "    print(f\"'{original_dtype_aqi}' dtype detected for 'aqi_value'. Attempting conversion to numeric.\")\n",
    "    df['aqi_value'] = pd.to_numeric(df['aqi_value'], errors='coerce')\n",
    "    if df['aqi_value'].isnull().any():\n",
    "        print(\"Warning: NaN values introduced in 'aqi_value' after conversion. Please inspect if unexpected.\")\n",
    "    else:\n",
    "        print(\"Conversion successful: 'aqi_value' is now numeric with no new NaNs.\")\n",
    "else:\n",
    "    print(f\"'aqi_value' is already of dtype: {original_dtype_aqi}. No conversion needed.\")\n",
    "\n",
    "# --- Step 5: Create new time-based features (year, month, month_name) ---\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['month_name'] = df['date'].dt.month_name()\n",
    "print(\"Created 'year', 'month', and 'month_name' columns.\")\n",
    "\n",
    "\n",
    "# --- Step 6: Export the main processed DataFrame to a CSV file for Power BI ---\n",
    "output_file_name = 'air_quality_processed_for_powerbi.csv'\n",
    "df.to_csv(output_file_name, index=False) # index=False prevents writing the Pandas DataFrame index as a column\n",
    "\n",
    "print(f\"\\n--- Export Complete ---\")\n",
    "print(f\"Your main processed DataFrame has been saved to: '{output_file_name}'\")\n",
    "print(f\"You can now import this CSV file into Power BI Desktop.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
